{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self):\n",
    "        self.dataFrame = []\n",
    "        self.nPC = 2\n",
    "        self.nKNN = 2\n",
    "        self.nKFolds = 5\n",
    "        self.hiddenLayers = [10,15,10]\n",
    "        self.activFunction = \"tanh\"\n",
    "        self.nIterations = 2500\n",
    "        self.momentum = 0.9\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.principalComponents = []\n",
    "        self.text=\"\"\n",
    "        self.nLines=0\n",
    "        self.nAttributes=0\n",
    "        self.nClasses=0\n",
    "        self.attributesName = []\n",
    "        self.data = []\n",
    "        self.dataPerAttribute = []\n",
    "        self.classes = []\n",
    "        self.principalDf = []\n",
    "        self.kn = []\n",
    "        self.nb = []\n",
    "        self.nn = []\n",
    "        self.scores_KK = []\n",
    "        self.scores_KN = []\n",
    "        self.scores_NN = []\n",
    "        self.split_names = []\n",
    "        self.model_names =['K-Nearest Neighbors','Naive Bayes','Neural Network']\n",
    "        self.eclf = []\n",
    "        self.eclf_scores = []\n",
    "    def setDF(self,dataFrame):\n",
    "        self.dataFrame = dataFrame\n",
    "    def readFile(self,filename):\n",
    "        # Read the file in the format given\n",
    "        self.text=\"\"\n",
    "        self.nLines=0\n",
    "        self.nAttributes=0\n",
    "        self.nClasses=0\n",
    "        self.attributesName = []\n",
    "        self.data = []\n",
    "        self.dataPerAttribute = []\n",
    "        self.classes = []\n",
    "        try:\n",
    "            with open(filename,\"r\") as file:\n",
    "                count=0\n",
    "                for line in file:\n",
    "                    if count < 3:\n",
    "                        if count == 0:\n",
    "                            self.nLines = int(line.strip())\n",
    "                        else:\n",
    "                            if count == 1:\n",
    "                                self.nAttributes = int(line.strip())\n",
    "                                for i in range(1,self.nAttributes+1):\n",
    "                                    self.attributesName.append(\"att\"+str(i))\n",
    "                                    self.dataPerAttribute.append([])\n",
    "                            else:\n",
    "                                if count == 2:\n",
    "                                    self.nClasses = int(line.strip())\n",
    "                    else:\n",
    "                        split_string_S = line.strip().split(',')\n",
    "\n",
    "                        count_split = 0\n",
    "                        split_string_n = []\n",
    "                        for split in split_string_S:\n",
    "                            if count_split >= self.nAttributes:\n",
    "                                split_string_n.append(int(split))\n",
    "                            else:\n",
    "                                split_string_n.append(float(split))\n",
    "                            count_split += 1\n",
    "\n",
    "                        self.data.append(split_string_n)\n",
    "                        self.classes.append(split_string_n[self.nAttributes])\n",
    "                        n_attribute = 0\n",
    "                        for attribute in split_string_n:\n",
    "                            if n_attribute >= self.nAttributes:\n",
    "                                break\n",
    "                            else:\n",
    "                                self.dataPerAttribute[n_attribute].append(attribute)\n",
    "                                n_attribute += 1\n",
    "                    count += 1\n",
    "                print(\"EOF reached\")\n",
    "                # Turning the data into a DataFrame python object\n",
    "                columns_ =  self.attributesName[:]\n",
    "                columns_.append(\"target\")\n",
    "                dataFrame = pd.DataFrame(data= self.data, columns=columns_)\n",
    "                self.setDF(dataFrame)\n",
    "        except FileNotFoundError:\n",
    "            text=\"Archivo no existe\"\n",
    "            exit()\n",
    "        finally:\n",
    "            file.close()\n",
    "            # print(str(nLines) + \"\\n\")\n",
    "            # print(str(nAttributes) + \"\\n\")\n",
    "            # print(str(nClasses) + \"\\n\")\n",
    "            # print(attributesName)\n",
    "            # print(data)\n",
    "    def transformData(self,nPC):\n",
    "        self.nPC = nPC\n",
    "        if self.nPC > self.nAttributes:\n",
    "            print(str(self.nAttributes) + \" is the maximum number of principal components\")\n",
    "            self.nPC = min([self.nAttributes,self.nPC])\n",
    "        else:\n",
    "            if self.nPC <= 0:\n",
    "                print(\"1 is the minimum number of principal components\")\n",
    "                self.nPC = max([1,self.nPC])\n",
    "        \n",
    "        # Separating out the features\n",
    "        self.x = self.dataFrame.loc[:, self.attributesName].values\n",
    "        # Separating out the target\n",
    "        self.y = self.dataFrame.loc[:,['target']].values\n",
    "        # Standardizing the features\n",
    "        self.x = StandardScaler().fit_transform(self.x)\n",
    "        \n",
    "        print (\"Creating PCA with \" + str(self.nPC) + \" components\")\n",
    "        pca = PCA(n_components=self.nPC)\n",
    "        self.principalComponents = pca.fit_transform(self.x)\n",
    "        pc_names = []\n",
    "        for i in range(1,self.nPC+1):\n",
    "            pc_names.append(\"principal component \"+ str(i))\n",
    "\n",
    "        self.principalDf = pd.DataFrame(data = self.principalComponents\n",
    "                     , columns = pc_names)\n",
    "    def buildModels(self,nKFolds=5,nKNN=5,hiddenLayers=[10,15,10],activFunction='tanh',nIterations=2500,momentum=0.9):\n",
    "        #Building models for the Ensemble\n",
    "        self.nKFolds = nKFolds\n",
    "        self.nKNN = nKNN\n",
    "        self.kn = KNeighborsClassifier(n_neighbors=nKNN)\n",
    "        self.nb = GaussianNB()\n",
    "        self.hiddenLayers = hiddenLayers\n",
    "        self.activFunction = activFunction\n",
    "        self.nIterations = nIterations\n",
    "        self.momentum = momentum\n",
    "        self.nn = MLPClassifier(hidden_layer_sizes=self.hiddenLayers,\n",
    "                                solver='sgd',\n",
    "                                activation=self.activFunction,\n",
    "                                max_iter=self.nIterations,\n",
    "                                momentum=self.momentum)\n",
    "        \n",
    "    def getScoreModels(self):\n",
    "        self.scores_KN = cross_val_score(self.kn, self.principalComponents, self.y.ravel(), cv=self.nKFolds)\n",
    "        self.scores_NB = cross_val_score(self.nb, self.principalComponents, self.y.ravel(), cv=self.nKFolds)\n",
    "        self.scores_NN = cross_val_score(self.nn, self.principalComponents, self.y.ravel(), cv=self.nKFolds)\n",
    "        self.split_names= []\n",
    "        \n",
    "        for i in range(1,self.nKFolds+1):\n",
    "            self.split_names.append(\"Fold \"+str(i))\n",
    "            \n",
    "        kk_df = pd.DataFrame(self.scores_KN,\n",
    "                           columns=['K-Nearest Neighbors'],\n",
    "                             index=self.split_names)\n",
    "        nb_df = pd.DataFrame(self.scores_NB,\n",
    "                           columns=['Naive Bayes'],\n",
    "                             index=self.split_names)\n",
    "        nn_df = pd.DataFrame(self.scores_NN,\n",
    "                           columns=['Neural Network'],\n",
    "                             index=self.split_names)\n",
    "        avg_models = [np.mean(self.scores_KN),\n",
    "                     np.mean(self.scores_NB),\n",
    "                     np.mean(self.scores_NN)]\n",
    "        avg_df = pd.DataFrame(avg_models,\n",
    "                              columns=['Normal Cross Validation Average'],index=self.model_names)\n",
    "        return kk_df,nb_df,nn_df,avg_df\n",
    "    def buildEnsemble(self,vote='hard'):\n",
    "        self.eclf = VotingClassifier(estimators=[('kn', self.kn), \n",
    "                                                 ('nb', self.nb), \n",
    "                                                 ('nnet', self.nn)], \n",
    "                                     voting=vote)\n",
    "    def trainEnsemble(self):\n",
    "        self.eclf_scores = cross_val_score(self.eclf, \n",
    "                                           self.principalComponents, \n",
    "                                           self.y.ravel(), \n",
    "                                           scoring='accuracy', \n",
    "                                           cv=self.nKFolds)\n",
    "        eclf_df = pd.DataFrame(self.eclf_scores,\n",
    "                           columns=['Ensemble'],\n",
    "                             index=self.split_names)\n",
    "        #print(\"Accuracy: %0.4f (+/- %0.4f)\" % (eclf_scores.mean(), eclf_scores.std() * 2))\n",
    "        return eclf_df,self.eclf_scores.mean(),self.eclf_scores.std()\n",
    "basic_ensemble = Ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOF reached\n",
      "Creating PCA with 8 components\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ensemble\n",
       "Fold 1  0.857143\n",
       "Fold 2  0.916667\n",
       "Fold 3  0.928571\n",
       "Fold 4  0.916667\n",
       "Fold 5  0.904762"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_ensemble.readFile(\"archivo.txt\")\n",
    "basic_ensemble.transformData(8)\n",
    "basic_ensemble.buildModels()\n",
    "d1,d2,d3,a = basic_ensemble.getScoreModels()\n",
    "basic_ensemble.buildEnsemble()\n",
    "e_df,e_mean,e_std = basic_ensemble.trainEnsemble()\n",
    "e_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
